{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "novel-gardening",
   "metadata": {},
   "source": [
    "### **D2APR: Aprendizado de M√°quina e Reconhecimento de Padr√µes** (IFSP, Campinas) <br/>\n",
    "**Prof**: Samuel Martins (Samuka) <br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. <br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-governor",
   "metadata": {},
   "source": [
    "#### Custom CSS style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-denial",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".dashed-box {\n",
    "    border: 1px dashed black !important;\n",
    "#    font-size: var(--jp-content-font-size1) !important;\n",
    "}\n",
    "\n",
    ".dashed-box table {\n",
    "\n",
    "}\n",
    "\n",
    ".dashed-box tr {\n",
    "    background-color: white !important;\n",
    "}\n",
    "        \n",
    ".alt-tab {\n",
    "    background-color: black;\n",
    "    color: #ffc351;\n",
    "    padding: 4px;\n",
    "    font-size: 1em;\n",
    "    font-weight: bold;\n",
    "    font-family: monospace;\n",
    "}\n",
    "// add your CSS styling here\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-immunology",
   "metadata": {},
   "source": [
    "<span style='font-size: 2.5em'><b>California Housing üè°</b></span><br/>\n",
    "<span style='font-size: 1.5em'>Predict the median housing price in California districts</span>\n",
    "\n",
    "<span style=\"background-color: #ffc351; padding: 4px; font-size: 1em;\"><b>Sprint #3</b></span>\n",
    "\n",
    "<img src=\"./imgs/california-flag.png\" width=300/>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-catering",
   "metadata": {},
   "source": [
    "## Before starting this notebook\n",
    "This jupyter notebook is designed for **experimental and teaching purposes**. <br/>\n",
    "Although it is (relatively) well organized, it aims at solving the _target problem_ by evaluating (and documenting) _different solutions_ for somes steps of the **machine learning pipeline** ‚Äî see the ***Machine Learning Project Checklist by xavecoding***. <br/>\n",
    "We tried to make this notebook as literally a _notebook_. Thus, it contains notes, drafts, comments, etc.<br/>\n",
    "\n",
    "For teaching purposes, some parts of the notebook may be _overcommented_. Moreover, to simulate a real development scenario, we will divide our solution and experiments into **\"sprints\"** in which each sprint has some goals (e.g., perform _feature selection_, train more ML models, ...). <br/>\n",
    "The **sprint goal** will be stated at the beginning of the notebook.\n",
    "\n",
    "A ***final notebook*** (or any other kind of presentation) that compiles and summarizes all sprints ‚Äî the target problem, solutions, and findings ‚Äî should be created later.\n",
    "\n",
    "#### Conventions\n",
    "\n",
    "<ul>\n",
    "    <li>üí° indicates a tip. </li>\n",
    "    <li> ‚ö†Ô∏è indicates a warning message. </li>\n",
    "    <li><span class='alt-tab'>alt tab</span> indicates and an extra content (<i>e.g.</i>, slides) to explain a given concept.</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-faculty",
   "metadata": {},
   "source": [
    "## üéØ Sprint Goals\n",
    "- Add new features\n",
    "- Normalize the data\n",
    "- Add a new model: Decision Tree Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-alloy",
   "metadata": {},
   "source": [
    "### 0. Imports and default settings for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-monroe",
   "metadata": {},
   "source": [
    "## üíΩ 2. Get the Data\n",
    "In the previous sprint, we have removed outliers from the entire dataset, split it into training and testing set, and preprocessed the training set (by fillin in missing values for `total_bedrooms`.) <br/>\n",
    "Both preprocessed training set and (raw) testing set were _saved to disk_. Let's use them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-power",
   "metadata": {},
   "source": [
    "### 2.2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "housing_train_pre = pd.read_csv('./datasets/housing_train_pre_sprint-2.csv')  # preprocessed train set\n",
    "housing_test = pd.read_csv('./datasets/housing_test_sprint-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-travel",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 5. Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-value",
   "metadata": {},
   "source": [
    "### 5.1. Adding new features (_dependent variable_) and the target outcome (_dependent variable_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-aircraft",
   "metadata": {},
   "source": [
    "The _total number of rooms_ in a district _is not very useful_ if you don‚Äôt know how many households there are. What you really want is **the number of rooms per household**. <br/>\n",
    "Similarly, the _total number of bedrooms_ by itself _is not very useful_: you probably want to compare it to the number of rooms. </br>\n",
    "And the **population per household** also seems like an interesting attribute combination to look at.\n",
    "\n",
    "Let‚Äôs create these new attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-durham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-fault",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-cookbook",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We could perform the EDA on the training set again but now considering these new features. <br/>\n",
    "For now, let's just check the **correlation** between these _new features_ with the _target outcome_.\n",
    "\n",
    "#### **Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-novel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "twenty-helena",
   "metadata": {},
   "source": [
    "Hey, not bad! The new `bedrooms_per_room attribute` is much more correlated with the `median house value` than the `total number of rooms or bedrooms`. <br/>\n",
    "Apparently, houses with a <i>lower bedroom/room ratio</i> tend to be <b>more expensive</b>. <br/>\n",
    "The `number of rooms per household` is also <b>more informative</b> than the `total number of rooms` in a district ‚Äî obviously the larger the houses, the more expensive they are.\n",
    "\n",
    "Another interesting point is the correlation between the <i>dummy variables</i> with the `median house value` -- not done in previous sprints. </br>\n",
    "The dummy variable `ocean_proximity_INLAND` has <i>strong negative correlation</i> with the `median house value` whereas `ocean_proximity_<1H OCEAN` has a <i>strong postive one</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-visiting",
   "metadata": {},
   "source": [
    "<table align=\"left\" class=\"dashed-box\">\n",
    "<tr>\n",
    "    <td>üí°</td>\n",
    "    <td>This round of exploration does not have to be absolutely thorough; the point is to quickly gain insights that helps you ot improve our models.</i></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td></td>\n",
    "    <td>But this is an <i>iterative process</i>: once you get a prototype up and running, you can analyze its output to gain more insights and come back to this exploration step.</td>\n",
    "</tr>\n",
    "</table><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-soviet",
   "metadata": {},
   "source": [
    "### 5.2. Separating the independent variables (features) and the _dependent variable_ (target outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_target = housing_train_pre['median_house_value'].copy()\n",
    "housing_train_pre = housing_train_pre.drop(columns=['median_house_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-lesbian",
   "metadata": {},
   "source": [
    "### 5.3. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-weight",
   "metadata": {},
   "source": [
    "With few exceptions, ML algorithms **don‚Äôt perform well** when the _input numerical attributes_ have **very different scales**. </br>\n",
    "For example, compare the scale of the attributes: `median_income` and `median_house_value`.\n",
    "\n",
    "Although **feature scaling** _is not_ necessarily for Linear Regression, we intend to evaluate other regression methods soon that may need that. So, we will perform it. <br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-marsh",
   "metadata": {},
   "source": [
    "There are two common ways to get all attributes to have the same scale: _min-max scaling_ and _standardization_.\n",
    "\n",
    "<img src='./imgs/normalization-vs-standardization.png' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-venue",
   "metadata": {},
   "source": [
    "<table align=\"left\" class=\"dashed-box\">\n",
    "<tr>\n",
    "    <td>‚ö†Ô∏è</td>\n",
    "    <td>Note that scaling the <i>target outcome</i> is generally <b>not required</b>.</i></td>\n",
    "</tr>\n",
    "</table><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-reggae",
   "metadata": {},
   "source": [
    "<table align=\"left\" class=\"dashed-box\">\n",
    "<tr>\n",
    "    <td>‚ö†Ô∏è</td>\n",
    "    <td>We <b>do not</b> need to scale the <i>binary dummy variables</i>.</i></td>\n",
    "</tr>\n",
    "</table><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-forum",
   "metadata": {},
   "source": [
    "<table align=\"left\" class=\"dashed-box\">\n",
    "<tr>\n",
    "    <td>‚ö†Ô∏è</td>\n",
    "    <td>As with all the transformations, it is important <i>to fit the scalers</i> to the <b>training data <i>only</i></b>, <b>not</b> to the <i>full dataset</i> (including the <i>test set</i>).</i></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td></td>\n",
    "    <td>Only then can you use them to transform the training set and the test set (and new data)..</i></td>\n",
    "</tr>\n",
    "</table><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-algebra",
   "metadata": {},
   "source": [
    "Let's use **Standardization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_pre.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_variables = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'rooms_per_household', 'bedrooms_per_room', 'population_per_household']\n",
    "dummy_variables = ['ocean_proximity_<1H OCEAN', 'ocean_proximity_INLAND', 'ocean_proximity_ISLAND', 'ocean_proximity_NEAR BAY', 'ocean_proximity_NEAR OCEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-slope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-impact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-garbage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-revelation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-brief",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-image",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-nursing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "familiar-desperate",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è 6. Train ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-supervisor",
   "metadata": {},
   "source": [
    "### 6.1. Getting the independent (features) and dependent variables (outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already have X_train\n",
    "y_train = housing_train_target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-intake",
   "metadata": {},
   "source": [
    "### 6.2. Training the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-costume",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regressor = LinearRegression()  # default parameters\n",
    "linear_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-upgrade",
   "metadata": {},
   "source": [
    "#### Decision Tree Regression\n",
    "This is a powerful model, capable of finding complex nonlinear relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-bread",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "disabled-profession",
   "metadata": {},
   "source": [
    "### 6.3. Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-morrison",
   "metadata": {},
   "source": [
    "#### **‚Üí Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-antibody",
   "metadata": {},
   "source": [
    "##### **Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_lin_reg = linear_regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-physiology",
   "metadata": {},
   "source": [
    "##### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lin_reg_r2 = r2_score(y_train, y_train_pred_lin_reg)\n",
    "print(f'R¬≤ linear regression = {lin_reg_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_reg_rmse = mean_squared_error(y_train, y_train_pred_lin_reg, squared=False)\n",
    "print(f'RMSE = {lin_reg_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-associate",
   "metadata": {},
   "source": [
    "The RMSE (\\\\$58,146) has slightly decreased compared to Sprint #2 (\\\\$58,689)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-beverage",
   "metadata": {},
   "source": [
    "#### **Visual Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_train_pred_lin_reg, y=y_train)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Median housing value - Prediction vs Real - Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_lin_reg = y_train - y_train_pred_lin_reg\n",
    "\n",
    "sns.scatterplot(x=y_train_pred_lin_reg, y=residual_lin_reg)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Median housing value - Prediction vs Residual - Linear Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-adrian",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "#### **‚Üí Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-preview",
   "metadata": {},
   "source": [
    "##### **Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_tree_reg = tree_regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-margin",
   "metadata": {},
   "source": [
    "##### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "tree_reg_r2 = r2_score(y_train, y_train_pred_tree_reg)\n",
    "print(f'R¬≤ decision tree regression = {tree_reg_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tree_reg_rmse = mean_squared_error(y_train, y_train_pred_tree_reg, squared=False)\n",
    "print(f'RMSE = {tree_reg_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-phrase",
   "metadata": {},
   "source": [
    "Wait, what!? No error at all? Could this model really be absolutely perfect? <br/>\n",
    "Of course, it is much more likely that the model has badly <b>overfit</b> the data.\n",
    "\n",
    "We'd better evaluate it by using **Cross-Validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-table",
   "metadata": {},
   "source": [
    "#### **Visual Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_train_pred_tree_reg, y=y_train)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Median housing value - Prediction vs Real - Decision Tree Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_tree_reg = y_train - y_train_pred_tree_reg\n",
    "\n",
    "sns.scatterplot(x=y_train_pred_lin_reg, y=residual_tree_reg)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Median housing value - Prediction vs Residual |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-quantity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
